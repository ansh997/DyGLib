{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminaries\n",
    "\n",
    "# scratch_location = r'/scratch/hmnshpl'\n",
    "import os\n",
    "import sys\n",
    "import heapq\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "dataset_name = 'wikipedia'\n",
    "scratch_location = rf'/scratch/{getpass.getuser()}'\n",
    "\n",
    "\n",
    "## Load Data\n",
    "# Load data and train val test split\n",
    "graph_df = pd.read_csv('{}/processed_data/{}/ml_{}.csv'.format(scratch_location,\n",
    "                                                            dataset_name,\n",
    "                                                            dataset_name)\n",
    "                    )\n",
    "edge_raw_features = np.load('{}/processed_data/{}/ml_{}.npy'.format(scratch_location,\n",
    "                                                                    dataset_name,\n",
    "                                                                    dataset_name)\n",
    "                            )\n",
    "node_raw_features = np.load('{}/processed_data/{}/ml_{}_node.npy'.format(scratch_location,\n",
    "                                                                        dataset_name,\n",
    "                                                                        dataset_name)\n",
    "                            )\n",
    "\n",
    "# Set the working directory to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')) # this might cause issue\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_data.temporal_pr import temporal_pagerank_with_timestamps, calc_timestamp_pagerank,\\\n",
    "    calc_inc_timestamp_pagerank, optimized_calc_inc_timestamp_pagerank,\\\n",
    "    get_temporal_pagerank, mean_shift_removal, mean_shift_removal2, compute_mean_shifts_with_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 0.15\n",
      "1862652.1 2218288.5999999996\n"
     ]
    }
   ],
   "source": [
    "# get the timestamp of validate and test set\n",
    "val_ratio = test_ratio = 0.15\n",
    "print(val_ratio, test_ratio)\n",
    "val_time, test_time = list(np.quantile(graph_df.ts, [(1 - val_ratio - test_ratio), (1 - test_ratio)]))\n",
    "print(val_time, test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "      <th>ts</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8229</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8229</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8230</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8229</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  u     i     ts  label  idx\n",
       "0           0  1  8228    0.0    0.0    1\n",
       "1           1  2  8229   36.0    0.0    2\n",
       "2           2  2  8229   77.0    0.0    3\n",
       "3           3  3  8230  131.0    0.0    4\n",
       "4           4  2  8229  150.0    0.0    5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_graph_df = graph_df[graph_df['ts'] < val_time]\n",
    "train_graph_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110232\n",
      "0.700001270050929\n"
     ]
    }
   ],
   "source": [
    "print(len(train_graph_df))\n",
    "print(len(train_graph_df) / len(graph_df))  # is 70% of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_graph = train_graph_df.copy(deep=True)\n",
    "upto=0.7\n",
    "metric='kl_divergence'\n",
    "# wasserstein, kl_divergence\n",
    "# jensen_shannon_divergence -- 1m47s\n",
    "# wasserstein -- 3m31s\n",
    "# kl_divergence -- 32s\n",
    "\n",
    "\n",
    "# tmp_graph = tmp_graph.sort_values(by=['u', 'i', 'ts'])\n",
    "\n",
    "# # Exclude the first and last rows based on 'u' and 'i'\n",
    "# grouped = tmp_graph.groupby(['u', 'i'])\n",
    "# modified_df = grouped.apply(lambda x: x.iloc[1:-1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_groups = len(grouped)\n",
    "# rows_removed = total_groups * 2 \n",
    "# total_rows_original = len(tmp_graph)\n",
    "# percentage_removed = (rows_removed / total_rows_original) * 100\n",
    "# percentage_removed, len(modified_df) / len(tmp_graph)\n",
    "\n",
    "# # Group by 'u' and 'i' and capture the first and last interactions\n",
    "# first_interactions = grouped.first().reset_index()\n",
    "# last_interactions = grouped.last().reset_index()\n",
    "\n",
    "# (len(first_interactions) + len(last_interactions)) / len(tmp_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for kl_divergence...: 100%|██████████| 110231/110231 [00:13<00:00, 8029.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# based on maximum mean shift strategy\n",
    "mean_shifts = compute_mean_shifts_with_metrics(tmp_graph, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove upto: 30.00% length of mean shift is:  110231 threshold_index=33069\n",
      "33069 30.00%\n",
      "33069 30.00%\n",
      "76258 0.6917954858843167\n",
      "data sampling successful.\n"
     ]
    }
   ],
   "source": [
    "print(f'remove upto: {(1-upto):.2%}', 'length of mean shift is: ', len(mean_shifts), end=' ')\n",
    "\n",
    "threshold_index = int(len(mean_shifts) * (1-upto))\n",
    "\n",
    "print(f'{threshold_index=}')\n",
    "top_mean_shifts = mean_shifts[:threshold_index]\n",
    "print(len(top_mean_shifts), f'{len(top_mean_shifts) / len(mean_shifts):.2%}' )\n",
    "\n",
    "top_x_percent_timestamps = [ts for ts, _ in top_mean_shifts]\n",
    "print(len(top_x_percent_timestamps), f'{len(top_x_percent_timestamps) / len(train_graph_df[\"ts\"]):.2%}')\n",
    "\n",
    "# sampled_df = modified_df[~modified_df['ts'].isin(top_x_percent_timestamps)]\n",
    "sampled_df = tmp_graph[~tmp_graph['ts'].isin(top_x_percent_timestamps)]\n",
    "print(len(sampled_df['ts']), len(sampled_df['ts']) / len(tmp_graph['ts']))\n",
    "print('data sampling successful.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6743232455185427"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_x_percent_timestamps) #  330\n",
    "len(tmp_graph['ts'])  # 110232\n",
    "\n",
    "len(set(tmp_graph['ts']).difference(set(top_x_percent_timestamps)))  # 106602\n",
    "len(set(tmp_graph['ts']).difference(set(top_x_percent_timestamps))) / len(tmp_graph['ts'])  # 106602"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'{scratch_location}/sparsified_data/{dataset_name}_{metric}_sparsified_{upto}.csv'\n",
    "# sampled_df.drop(['Unnamed: 0'], axis=1).to_csv(filename)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsify_data(tmp_graph, metric, upto, dataset_name, save=False):\n",
    "    # tmp_graph = tmp_graph.sort_values(by=['u', 'i', 'ts'])\n",
    "\n",
    "    # # Exclude the first and last rows based on 'u' and 'i'\n",
    "    # grouped = tmp_graph.groupby(['u', 'i'])\n",
    "    # modified_df = grouped.apply(lambda x: x.iloc[1:-1]).reset_index(drop=True)\n",
    "    \n",
    "    # based on maximum mean shift strategy\n",
    "    mean_shifts = compute_mean_shifts_with_metrics(tmp_graph, metric=metric)\n",
    "\n",
    "    print('back to sparsify_data file....')\n",
    "\n",
    "    threshold_index = int(len(mean_shifts) * (1-upto))\n",
    "    top_mean_shifts = mean_shifts[:threshold_index]\n",
    "\n",
    "    top_x_percent_timestamps = [ts for ts, _ in top_mean_shifts]\n",
    "\n",
    "    sampled_df = tmp_graph[~tmp_graph['ts'].isin(top_x_percent_timestamps)]\n",
    "    print('data sampling successful.')\n",
    "    \n",
    "    if save:\n",
    "        filename = f'{scratch_location}/sparsified_data/{dataset_name}_{metric}_sparsified_{upto}.csv'\n",
    "        sampled_df.drop(['Unnamed: 0'], axis=1).to_csv(filename)\n",
    "        print(filename, ' saved.')\n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "\tcosine Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for cosine...: 100%|██████████| 110231/110231 [00:05<00:00, 19446.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_cosine_sparsified_0.9.csv  saved.\n",
      "done\n",
      "\teuclidean Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for euclidean...: 100%|██████████| 110231/110231 [00:04<00:00, 25896.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_euclidean_sparsified_0.9.csv  saved.\n",
      "done\n",
      "\tjaccard Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for jaccard...: 100%|██████████| 110231/110231 [00:19<00:00, 5595.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_jaccard_sparsified_0.9.csv  saved.\n",
      "done\n",
      "\tkl_divergence Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for kl_divergence...: 100%|██████████| 110231/110231 [00:14<00:00, 7626.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_kl_divergence_sparsified_0.9.csv  saved.\n",
      "done\n",
      "\tjensen_shannon_divergence Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for jensen_shannon_divergence...: 100%|██████████| 110231/110231 [00:35<00:00, 3137.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_jensen_shannon_divergence_sparsified_0.9.csv  saved.\n",
      "done\n",
      "\twasserstein Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for wasserstein...: 100%|██████████| 110231/110231 [02:57<00:00, 620.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_wasserstein_sparsified_0.9.csv  saved.\n",
      "done\n",
      "0.8\n",
      "\tcosine Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for cosine...: 100%|██████████| 110231/110231 [00:05<00:00, 19593.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_cosine_sparsified_0.8.csv  saved.\n",
      "done\n",
      "\teuclidean Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for euclidean...: 100%|██████████| 110231/110231 [00:04<00:00, 25997.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_euclidean_sparsified_0.8.csv  saved.\n",
      "done\n",
      "\tjaccard Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for jaccard...: 100%|██████████| 110231/110231 [00:19<00:00, 5521.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_jaccard_sparsified_0.8.csv  saved.\n",
      "done\n",
      "\tkl_divergence Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for kl_divergence...: 100%|██████████| 110231/110231 [00:14<00:00, 7576.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_kl_divergence_sparsified_0.8.csv  saved.\n",
      "done\n",
      "\tjensen_shannon_divergence Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for jensen_shannon_divergence...: 100%|██████████| 110231/110231 [00:35<00:00, 3111.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_jensen_shannon_divergence_sparsified_0.8.csv  saved.\n",
      "done\n",
      "\twasserstein Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for wasserstein...: 100%|██████████| 110231/110231 [02:57<00:00, 619.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_wasserstein_sparsified_0.8.csv  saved.\n",
      "done\n",
      "0.7\n",
      "\tcosine Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for cosine...: 100%|██████████| 110231/110231 [00:05<00:00, 19504.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_cosine_sparsified_0.7.csv  saved.\n",
      "done\n",
      "\teuclidean Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for euclidean...: 100%|██████████| 110231/110231 [00:04<00:00, 26001.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_euclidean_sparsified_0.7.csv  saved.\n",
      "done\n",
      "\tjaccard Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for jaccard...: 100%|██████████| 110231/110231 [00:19<00:00, 5569.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_jaccard_sparsified_0.7.csv  saved.\n",
      "done\n",
      "\tkl_divergence Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for kl_divergence...: 100%|██████████| 110231/110231 [00:14<00:00, 7530.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_kl_divergence_sparsified_0.7.csv  saved.\n",
      "done\n",
      "\tjensen_shannon_divergence Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for jensen_shannon_divergence...: 100%|██████████| 110231/110231 [00:35<00:00, 3082.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_jensen_shannon_divergence_sparsified_0.7.csv  saved.\n",
      "done\n",
      "\twasserstein Starting mean shift and metrics computation...\n",
      "Running temporal PageRank computation...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Temporal PageRank computation completed.\n",
      "Sorting timestamps...\n",
      "Sorting completed.\n",
      "Calculating mean shifts and distance metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing for wasserstein...: 100%|██████████| 110231/110231 [02:59<00:00, 614.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean shifts and metrics calculation completed.\n",
      "Sorting by the selected metric completed.\n",
      "back to sparsify_data file....\n",
      "data sampling successful.\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_wasserstein_sparsified_0.7.csv  saved.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "list_of_upto = [0.9, 0.8, 0.7]\n",
    "metrics= ['cosine', 'euclidean', 'jaccard','kl_divergence', 'jensen_shannon_divergence', 'wasserstein']\n",
    "tmp_graph = train_graph_df.copy(deep=True)\n",
    "\n",
    "for upto in list_of_upto:\n",
    "    print(f'{upto}')\n",
    "    for metric in metrics:\n",
    "        print(f'\\t{metric}', end=' ')\n",
    "        sampled_df = sparsify_data(tmp_graph, metric, upto, dataset_name, save=True)\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sampled_df=pd.read_csv(filename)\n",
    "# Remove columns with 'Unnamed:' in their name\n",
    "sampled_df = sampled_df.loc[:, ~sampled_df.columns.str.contains('^Unnamed')]\n",
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shell_script(result_path, save_folder, email, dataset_name, model_name, patch_size,\n",
    "                        max_input_sequence_length, num_runs, gpu, sparsify, strategy, sampling_upto,\n",
    "                        num_cpus, num_gpus, gnode_name):\n",
    "    \n",
    "    # set Default variables\n",
    "    result_path = \"/home2/hmnshpl/projects/results\" if result_path is None else result_path\n",
    "    save_folder = \"DygLib\" if save_folder is None else save_folder\n",
    "    email = \"himanshu.pal@research.iiit.ac.in\" if email is None else email\n",
    "    dataset_name = \"wikipedia\" if dataset_name is None else dataset_name\n",
    "    model_name = \"TGN\" if model_name is None else model_name\n",
    "    patch_size = 2 if patch_size is None else patch_size\n",
    "    max_input_sequence_length = 64 if max_input_sequence_length is None else max_input_sequence_length\n",
    "    num_runs = 5 if num_runs is None else num_runs\n",
    "    gpu = 0 if gpu is None else gpu\n",
    "    sparsify = True if sparsify is None else sparsify\n",
    "    strategy = \"ts_tpr_remove_cosine\" if strategy is None else strategy\n",
    "    sampling_upto = 0.7 if sampling_upto is None else sampling_upto\n",
    "    num_cpus = 9 if num_cpus is None else num_cpus\n",
    "    num_gpus = 1 if num_gpus is None else num_gpus\n",
    "    if gnode_name is None or 'gnode' not in gnode_name:\n",
    "        raise ValueError(\"Please provide a valid gnode.\")\n",
    "\n",
    "    # Generate shell script content\n",
    "    script_content = f\"\"\"#!/bin/bash\n",
    "#SBATCH -A research\n",
    "#SBATCH -n {num_cpus}\n",
    "#SBATCH --gres=gpu:{num_gpus}\n",
    "#SBATCH --mem-per-cpu=2G\n",
    "#SBATCH --output={result_path}/{save_folder}/Link_Prediciton_{strategy}_{sampling_upto}.txt\n",
    "#SBATCH --nodelist {gnode_name}\n",
    "#SBATCH --time=96:00:00\n",
    "#SBATCH --mail-user={email}\n",
    "#SBATCH --mail-type=ALL\n",
    "\n",
    "source ~/.bashrc\n",
    "\n",
    "conda activate tg\n",
    "\n",
    "python train_link_prediction.py --dataset_name {dataset_name} --model_name {model_name} --patch_size {patch_size} --max_input_sequence_length {max_input_sequence_length} --num_runs {num_runs} --gpu {gpu} --sparsify {sparsify} --strategy {strategy} --sampling_upto {sampling_upto}\n",
    "    \"\"\"\n",
    "\n",
    "    # Specify the output filename dynamically\n",
    "    output_filename = f\"../LP_{strategy}_{sampling_upto}.sh\"\n",
    "\n",
    "    # Write to file\n",
    "    with open(output_filename, \"w\") as file:\n",
    "        file.write(script_content)\n",
    "\n",
    "    print(f\"Shell script '{output_filename}' has been successfully generated.\")\n",
    "\n",
    "# Example usage\n",
    "# generate_shell_script(\"/home2/hmnshpl/projects/results\", \"DygLib\", \"himanshu.pal@research.iiit.ac.in\",\n",
    "#                     \"wikipedia\", \"TGN\", 2, 64, 5, 0, True, \"ts_tpr_remove_wasserstein\", 0.7, 9, 1, 'gnode085')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shell script '../LP_ts_tpr_remove_MSS_0.7.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_MSS_0.8.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_MSS_0.9.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_mss_2_0.7.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_mss_2_0.8.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_mss_2_0.9.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_kl_divergence_0.7.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_kl_divergence_0.8.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_kl_divergence_0.9.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_jensen_shannon_divergence_0.7.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_jensen_shannon_divergence_0.8.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_jensen_shannon_divergence_0.9.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_cosine_0.7.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_cosine_0.8.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_cosine_0.9.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_euclidean_0.7.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_euclidean_0.8.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_euclidean_0.9.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_jaccard_0.7.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_jaccard_0.8.sh' has been successfully generated.\n",
      "Shell script '../LP_ts_tpr_remove_jaccard_0.9.sh' has been successfully generated.\n"
     ]
    }
   ],
   "source": [
    "available_gnodes =  ['gnode074', 'gnode078', 'gnode067']\n",
    "strategies = ['ts_tpr_remove_MSS', 'ts_tpr_remove_mss_2', 'ts_tpr_remove_kl_divergence', 'ts_tpr_remove_jensen_shannon_divergence',\n",
    "            'ts_tpr_remove_cosine', 'ts_tpr_remove_euclidean', 'ts_tpr_remove_jaccard']\n",
    "samplings = [0.7, 0.8, 0.9]\n",
    "\n",
    "# Mapping of strategies to gnodes\n",
    "strategy_to_gnode = {\n",
    "    'ts_tpr_remove_wasserstein': 'gnode074',\n",
    "    'ts_tpr_remove_kl_divergence': 'gnode078',\n",
    "    'ts_tpr_remove_jensen_shannon_divergence': 'gnode067',\n",
    "    'ts_tpr_remove_MSS':'gnode074',\n",
    "    'ts_tpr_remove_mss_2':'gnode078',\n",
    "    'ts_tpr_remove_cosine': 'gnode067',\n",
    "    'ts_tpr_remove_euclidean': 'gnode074',\n",
    "    'ts_tpr_remove_jaccard': 'gnode078', \n",
    "}\n",
    "\n",
    "for strategy in strategies:\n",
    "    for sampling in samplings:\n",
    "        gnode = strategy_to_gnode[strategy]\n",
    "        generate_shell_script(\"/home2/hmnshpl/projects/results\", \"DygLib\", \"himanshu.pal@research.iiit.ac.in\",\n",
    "                    \"wikipedia\", \"TGN\", 2, 64, 5, 0, True, strategy, sampling, 9, 1, gnode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in mss removal method....\n",
      "running temporal page rank method...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Done.\n",
      "sorting started....\n",
      "sorting Completed.\n",
      "Before calc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running mean shift: 100%|██████████| 110231/110231 [00:04<00:00, 24970.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "mean shift calc done....\n",
      "back to sparsify_data file....\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_mss2_sparsified_0.9.csv  saved.\n",
      "in mss removal method....\n",
      "running temporal page rank method...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Done.\n",
      "sorting started....\n",
      "sorting Completed.\n",
      "Before calc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running mean shift: 100%|██████████| 110231/110231 [00:04<00:00, 26891.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "mean shift calc done....\n",
      "back to sparsify_data file....\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_mss2_sparsified_0.8.csv  saved.\n",
      "in mss removal method....\n",
      "running temporal page rank method...\n",
      "\t inside tpr heap method\n",
      "\t heapify successful\n",
      "\t out of loop.\n",
      "Done.\n",
      "sorting started....\n",
      "sorting Completed.\n",
      "Before calc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running mean shift: 100%|██████████| 110231/110231 [00:04<00:00, 26944.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "mean shift calc done....\n",
      "back to sparsify_data file....\n",
      "/scratch/hmnshpl/sparsified_data/wikipedia_mss2_sparsified_0.7.csv  saved.\n"
     ]
    }
   ],
   "source": [
    "tmp_graph = train_graph_df.copy(deep=True)\n",
    "# upto=0.7\n",
    "list_of_upto = [0.9, 0.8, 0.7]\n",
    "\n",
    "for upto in list_of_upto:\n",
    "    tmp_graph = tmp_graph.sort_values(by=['u', 'i', 'ts'])\n",
    "\n",
    "    # Exclude the first and last rows based on 'u' and 'i'\n",
    "    grouped = tmp_graph.groupby(['u', 'i'])\n",
    "    modified_df = grouped.apply(lambda x: x.iloc[1:-1]).reset_index(drop=True)\n",
    "\n",
    "    mean_shifts = mean_shift_removal2(tmp_graph)\n",
    "\n",
    "    print('back to sparsify_data file....')\n",
    "\n",
    "    threshold_index = int(len(mean_shifts) * (1-upto))\n",
    "    top_mean_shifts = mean_shifts[:threshold_index]\n",
    "\n",
    "    top_x_percent_timestamps = [ts for ts, _ in top_mean_shifts]\n",
    "\n",
    "    sampled_df = modified_df[~modified_df['ts'].isin(top_x_percent_timestamps)]\n",
    "\n",
    "    filename = f'{scratch_location}/sparsified_data/{dataset_name}_mss2_sparsified_{upto}.csv'\n",
    "    sampled_df.drop(['Unnamed: 0'], axis=1).to_csv(filename)\n",
    "    print(filename, ' saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
