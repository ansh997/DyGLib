{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminaries\n",
    "\n",
    "# scratch_location = r'/scratch/hmnshpl'\n",
    "import os\n",
    "import sys\n",
    "import heapq\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "dataset_name = 'wikipedia'\n",
    "scratch_location = rf'/scratch/{getpass.getuser()}'\n",
    "\n",
    "\n",
    "## Load Data\n",
    "# Load data and train val test split\n",
    "graph_df = pd.read_csv('{}/processed_data/{}/ml_{}.csv'.format(scratch_location,\n",
    "                                                            dataset_name,\n",
    "                                                            dataset_name)\n",
    "                    )\n",
    "edge_raw_features = np.load('{}/processed_data/{}/ml_{}.npy'.format(scratch_location,\n",
    "                                                                    dataset_name,\n",
    "                                                                    dataset_name)\n",
    "                            )\n",
    "node_raw_features = np.load('{}/processed_data/{}/ml_{}_node.npy'.format(scratch_location,\n",
    "                                                                        dataset_name,\n",
    "                                                                        dataset_name)\n",
    "                            )\n",
    "\n",
    "# Set the working directory to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')) # this might cause issue\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperal EdgeRank Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_pagerank_heap_np(E, beta, alpha, check_evolution=False):\n",
    "    # print('\\t inside tpr heap method')\n",
    "    # Convert edges to a NumPy array\n",
    "    E = np.array(E, dtype=[('u', int), ('v', int), ('t', float)])\n",
    "    \n",
    "    # Get the maximum node index to size the r and s arrays appropriately\n",
    "    max_node = max(E['u'].max(), E['v'].max())\n",
    "    \n",
    "    # Initialize r and s arrays\n",
    "    r = np.zeros(max_node + 1)\n",
    "    s = np.zeros(max_node + 1)\n",
    "    \n",
    "    ts_tpr = [] if check_evolution else None\n",
    "    \n",
    "    # Use a heap to efficiently process edges in time order\n",
    "    heap = [(t, u, v) for u, v, t in E]\n",
    "    heapq.heapify(heap)\n",
    "    # print('\\t heapify successful')\n",
    "    while heap:\n",
    "        t, u, v = heapq.heappop(heap)\n",
    "        \n",
    "        # Update r and s values\n",
    "        delta = 1 - alpha\n",
    "        r[u] += delta\n",
    "        s[u] += delta\n",
    "        r[v] += s[u] * alpha\n",
    "        \n",
    "        if beta < 1:\n",
    "            s_v_increment = s[u] * (1 - beta) * alpha\n",
    "            s[v] += s_v_increment\n",
    "            s[u] *= beta\n",
    "        else:\n",
    "            s[v] += s[u] * alpha\n",
    "            s[u] = 0\n",
    "        \n",
    "        # Store evolution if required\n",
    "        if check_evolution:\n",
    "            # ts_tpr.append((t, r.copy()))  # Store r values at current timestamp\n",
    "            # Normalize r before appending\n",
    "            total_r = r.sum()\n",
    "            if total_r > 0:\n",
    "                ts_tpr.append((t, r.copy() / total_r))\n",
    "    # print('\\t out of loop.')\n",
    "    \n",
    "    # Normalize r\n",
    "    total_r = r.sum()\n",
    "    if total_r > 0:\n",
    "        r /= total_r\n",
    "    \n",
    "    if check_evolution:\n",
    "        ts_tpr = np.array(ts_tpr, dtype=[('t', float), ('r', float, max_node + 1)])\n",
    "    \n",
    "    return r, ts_tpr\n",
    "\n",
    "def compute_temporal_outgoing_degree(E):\n",
    "    E = np.array(E, dtype=[('u', int), ('v', int), ('t', float)])\n",
    "    outgoing_degree = defaultdict(int)\n",
    "    temporal_outgoing_degree = defaultdict(list)\n",
    "    heap = [(t, u, v) for u, v, t in E]\n",
    "    heapq.heapify(heap)\n",
    "    while heap:\n",
    "        t, u, v = heapq.heappop(heap)\n",
    "        outgoing_degree[u] += 1\n",
    "        for node in outgoing_degree:\n",
    "            temporal_outgoing_degree[node].append((t, outgoing_degree[node]))\n",
    "    return temporal_outgoing_degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract nodes, edges, and timestamps\n",
    "edges = graph_df[['u', 'i', 'ts']].values\n",
    "nodes = np.unique(edges[:, :2])  # Get unique nodes from edges\n",
    "\n",
    "# Convert E to a more readable format if needed\n",
    "edges_new = [(int(u), int(v), float(t)) for u, v, t in edges]\n",
    "\n",
    "beta = 0.85\n",
    "alpha = 0.15\n",
    "\n",
    "r2, ts_tpr= temporal_pagerank_heap_np(edges_new, beta, alpha, True)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_temporal_outgoing_degree(E):\n",
    "    E = np.array(E, dtype=[('u', int), ('v', int), ('t', float)])\n",
    "    outgoing_degree = defaultdict(int)\n",
    "    temporal_outgoing_degree = defaultdict(list)\n",
    "    heap = [(t, u, v) for u, v, t in E]\n",
    "    heapq.heapify(heap)\n",
    "    while heap:\n",
    "        t, u, v = heapq.heappop(heap)\n",
    "        outgoing_degree[u] += 1\n",
    "        for node in outgoing_degree:\n",
    "            temporal_outgoing_degree[node].append((t, outgoing_degree[node]))\n",
    "    return temporal_outgoing_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def compute_temporal_edgerank(E, beta, alpha):\n",
    "    _, ts_tpr = temporal_pagerank_heap_np(E, beta, alpha, check_evolution=True)\n",
    "    print(len(ts_tpr))\n",
    "    temporal_outgoing_degree = compute_temporal_outgoing_degree(E)\n",
    "    temporal_edgerank = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    for tpr in tqdm(ts_tpr, desc='Calculating Temporal EdgeRank'):\n",
    "        t, r = tpr['t'], tpr['r']\n",
    "        for u, v, t_ev in E:\n",
    "            if t_ev <= t:\n",
    "                if u in r and u in temporal_outgoing_degree:\n",
    "                    current_degree = [d for time, d in temporal_outgoing_degree[u] if time <= t][-1]\n",
    "                    if current_degree > 0:\n",
    "                        edge_rank = r[u] / current_degree\n",
    "                    else:\n",
    "                        edge_rank = 0\n",
    "                    print('Add rank...')\n",
    "                    temporal_edgerank[u][v].append((t, edge_rank))\n",
    "    \n",
    "    return temporal_edgerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "E = [\n",
    "    (1, 2, 1.0),\n",
    "    (2, 3, 2.0),\n",
    "    (1, 3, 3.0),\n",
    "    (1, 2, 4.0),\n",
    "    (2, 1, 5.0)\n",
    "]\n",
    "\n",
    "temporal_edgerank = compute_temporal_edgerank(E, beta, alpha)\n",
    "\n",
    "# Print Temporal EdgeRank\n",
    "for u in temporal_edgerank:\n",
    "    for v in temporal_edgerank[u]:\n",
    "        print(f\"Edge ({u}, {v}) Temporal EdgeRank over time: {temporal_edgerank[u][v]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ts_tpr = temporal_pagerank_heap_np(E, beta, alpha, check_evolution=True)\n",
    "ts_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_outgoing_degree = compute_temporal_outgoing_degree(E)\n",
    "temporal_outgoing_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_edgerank = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for tpr in tqdm(ts_tpr, desc='Calculating Temporal EdgeRank'):\n",
    "    t, r = tpr['t'], tpr['r']\n",
    "    for u, v, t_ev in E:\n",
    "        if t_ev <= t:\n",
    "            if u in temporal_outgoing_degree:\n",
    "                current_degree = [d for time, d in temporal_outgoing_degree[u] if time <= t][-1]\n",
    "                if current_degree > 0:\n",
    "                    edge_rank = r[u] / current_degree\n",
    "                else:\n",
    "                    edge_rank = 0\n",
    "                print('Add rank...')\n",
    "                temporal_edgerank[u][v].append((t, edge_rank))\n",
    "                \n",
    "len(temporal_edgerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u, v, t_ev in E:\n",
    "    r = dict(ts_tpr)[t_ev]\n",
    "    if u in temporal_outgoing_degree:\n",
    "        current_degree = [d for time, d in temporal_outgoing_degree[u] if time <= t][-1]\n",
    "        if current_degree > 0:\n",
    "            edge_rank = r[u] / current_degree\n",
    "        else:\n",
    "            edge_rank = 0\n",
    "        print('Add rank...')\n",
    "        temporal_edgerank[u][v].append((t, edge_rank))\n",
    "len(temporal_edgerank)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_edgerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_edgerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_temporal_edgerank_with_time_decay_smoothening(E, beta, alpha, decay_factor=0.9):\n",
    "    _, ts_tpr = temporal_pagerank_heap_np(E, beta, alpha, check_evolution=True)\n",
    "    temporal_outgoing_degree = compute_temporal_outgoing_degree(E)\n",
    "    assert len(ts_tpr) > 0, 'Check1'\n",
    "    assert len(temporal_outgoing_degree) > 0, 'Check2'\n",
    "    temporal_edgerank = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    def smooth_degree(degree):\n",
    "        return degree ** 0.5  # Smoothing function (e.g., square root)\n",
    "    \n",
    "    for tpr in ts_tpr:\n",
    "        t, r = tpr['t'], tpr['r']\n",
    "        print(f'for {t=}')\n",
    "        for u, v, t_ev in E:\n",
    "            print(f'\\tProcessing {t_ev=} for {(u, v)}', end=' ')\n",
    "            if t_ev <= t:\n",
    "                print('started: ')\n",
    "                current_degrees = [d for time, d in temporal_outgoing_degree[u] if time <= t]\n",
    "                if current_degrees:\n",
    "                    current_degree = smooth_degree(current_degrees[-1])\n",
    "                    if current_degree > 0:\n",
    "                        time_diff = t - t_ev\n",
    "                        edge_rank = (r[u] / current_degree) * (decay_factor ** time_diff)\n",
    "                    else:\n",
    "                        edge_rank = 0\n",
    "                    temporal_edgerank[u][v].append((t, edge_rank))\n",
    "                    print(f'\\t\\tappended {(u, v)} for time {t}')\n",
    "            else:\n",
    "                print('Unprocessed.', end='\\n')\n",
    "    assert len(temporal_edgerank) != 0, 'Check2'\n",
    "    \n",
    "    return temporal_edgerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_temporal_edgerank_with_time_decay_smoothening(E, beta, alpha, decay_factor=0.9):\n",
    "    _, ts_tpr = temporal_pagerank_heap_np(E, beta, alpha, check_evolution=True)\n",
    "    temporal_outgoing_degree = compute_temporal_outgoing_degree(E)\n",
    "    assert len(ts_tpr) > 0, 'Check1'\n",
    "    assert len(temporal_outgoing_degree) > 0, 'Check2'\n",
    "    temporal_edgerank = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    def smooth_degree(degree):\n",
    "        return degree ** 0.5  # Smoothing function (e.g., square root)\n",
    "    \n",
    "    for tpr in ts_tpr:\n",
    "        t, r = tpr['t'], tpr['r']\n",
    "        print(f'Processing timestamp {t}')\n",
    "        \n",
    "        processed_edges = set()  # Track processed (u, v, t_ev) tuples\n",
    "        \n",
    "        for u, v, t_ev in E:\n",
    "            print(f'\\t{(u, v, t_ev)}', end = ' ')\n",
    "            if (u, v, t_ev) in processed_edges:\n",
    "                print(f' already processed. Skipped...')\n",
    "                continue  # Skip if already processed\n",
    "            # print('')\n",
    "            if t_ev <= t: # changed here from t_ev <= t to t_ev == t\n",
    "                print(f'\\tProcessing edge ({u}, {v}) at time {t_ev} for timestamp {t}')\n",
    "                \n",
    "                # Retrieve degrees up to current timestamp t\n",
    "                current_degrees = [d for time, d in temporal_outgoing_degree[u] if time <= t]  # changed here from time <= t to time == t\n",
    "                if current_degrees:\n",
    "                    current_degree = smooth_degree(current_degrees[-1])\n",
    "                    if current_degree > 0:\n",
    "                        time_diff = t - t_ev\n",
    "                        edge_rank = (r[u] / current_degree) * (decay_factor ** time_diff)\n",
    "                    else:\n",
    "                        edge_rank = 0\n",
    "                    temporal_edgerank[u][v].append((t, edge_rank))\n",
    "                    print(f'\\t\\t\\t\\t\\tAppended edge rank: ({u}, {v}, {t}, {edge_rank})')\n",
    "                else:\n",
    "                    print(f'\\t\\tNo valid degree for user {u} at time {t}')\n",
    "                \n",
    "                processed_edges.add((u, v, t_ev))  # Mark this edge as processed\n",
    "            else:\n",
    "                print(f'\\tSkipping edge ({u}, {v}) at time {t_ev} as it is not != {t}')\n",
    "    \n",
    "    assert len(temporal_edgerank) != 0, 'Check2'\n",
    "    return temporal_edgerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_temporal_edgerank_with_time_decay_smoothening(E, beta, alpha, decay_factor=0.9):\n",
    "    _, ts_tpr = temporal_pagerank_heap_np(E, beta, alpha, check_evolution=True)\n",
    "    temporal_outgoing_degree = compute_temporal_outgoing_degree(E)\n",
    "    assert len(ts_tpr) > 0, 'Check1'\n",
    "    assert len(temporal_outgoing_degree) > 0, 'Check2'\n",
    "    temporal_edgerank = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    def smooth_degree(degree):\n",
    "        return degree ** 0.5  # Smoothing function (e.g., square root)\n",
    "    \n",
    "    # Create a mapping from edges to their timestamps\n",
    "    edge_to_time = defaultdict(list)\n",
    "    for u, v, t_ev in E:\n",
    "        edge_to_time[(u, v)].append(t_ev)\n",
    "    \n",
    "    for tpr in ts_tpr:\n",
    "        t, r = tpr['t'], tpr['r']\n",
    "        print(f'Processing timestamp {t}')\n",
    "        \n",
    "        for (u, v), times in edge_to_time.items():\n",
    "            # Process each edge only if it has not been processed for this timestamp\n",
    "            for t_ev in times:\n",
    "                if t_ev <= t:\n",
    "                    print(f'\\tProcessing edge ({u}, {v}) at time {t_ev} for timestamp {t}')\n",
    "                    \n",
    "                    # Retrieve degrees up to current timestamp t\n",
    "                    current_degrees = [d for time, d in temporal_outgoing_degree[u] if time <= t]\n",
    "                    if current_degrees:\n",
    "                        current_degree = smooth_degree(current_degrees[-1])\n",
    "                        if current_degree > 0:\n",
    "                            time_diff = t - t_ev\n",
    "                            edge_rank = (r[u] / current_degree) * (decay_factor ** time_diff)\n",
    "                        else:\n",
    "                            edge_rank = 0\n",
    "                        temporal_edgerank[u][v].append((t, edge_rank))\n",
    "                        print(f'\\t\\t\\t\\t\\tAppended edge rank: ({u}, {v}, {t}, {edge_rank})')\n",
    "                    \n",
    "                    # Stop processing this edge after the first valid timestamp\n",
    "                    break\n",
    "                else:\n",
    "                    print(f'\\tSkipping edge ({u}, {v}) at time {t_ev} as it is not <= {t}')\n",
    "    \n",
    "    assert len(temporal_edgerank) != 0, 'Check2'\n",
    "    return temporal_edgerank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_edgerank = compute_temporal_edgerank_with_time_decay_smoothening(E, beta, alpha, decay_factor=0.9)\n",
    "# (temporal_edgerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sort the inner defaultdict\n",
    "def sort_inner_dict(d):\n",
    "    return {k: sorted(v, key=lambda x: x[0]) for k, v in d.items()}\n",
    "\n",
    "# Sort the inner default dicts\n",
    "sorted_data = {k: sort_inner_dict(v) for k, v in temporal_edgerank.items()}\n",
    "\n",
    "# Sort the outer defaultdict\n",
    "sorted_data = dict(sorted(sorted_data.items()))\n",
    "\n",
    "print(sorted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the defaultdict into a list of records [u, i, ts, value]\n",
    "records = []\n",
    "for u, inner_dict in temporal_edgerank.items():\n",
    "    for i, values in inner_dict.items():\n",
    "        for ts, value in values:\n",
    "            records.append([u, i, ts, value])\n",
    "\n",
    "# Create a DataFrame from the records\n",
    "df = pd.DataFrame(records, columns=['u', 'i', 'ts', 'value'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(E)\n",
    "# Rename the columns in df2 to match those in df1\n",
    "df2.columns = ['u', 'i', 'ts']\n",
    "\n",
    "# Merge the DataFrames on 'u', 'i', and 'ts'\n",
    "merged_df = pd.merge(df2, df, on=['u', 'i', 'ts'])\n",
    "\n",
    "(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df2), len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract nodes, edges, and timestamps\n",
    "edges = graph_df[['u', 'i', 'ts']].values\n",
    "nodes = np.unique(edges[:, :2])  # Get unique nodes from edges\n",
    "\n",
    "# Convert E to a more readable format if needed\n",
    "edges_new = [(int(u), int(v), float(t)) for u, v, t in edges]\n",
    "\n",
    "beta = 0.85\n",
    "alpha = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2, ts_tpr= temporal_pagerank_heap_np(edges_new, beta, alpha, True)\n",
    "# print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal_outgoing_degree = compute_temporal_outgoing_degree(edges_new)\n",
    "# temporal_outgoing_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal_outgoing_degree[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_temporal_outgoing_degree(E):\n",
    "#     E = np.array(E, dtype=[('u', int), ('v', int), ('t', float)])\n",
    "#     outgoing_degree = defaultdict(int)\n",
    "#     temporal_outgoing_degree = defaultdict(list)\n",
    "    \n",
    "#     # Sort the edges by time\n",
    "#     E = np.sort(E, order='t')\n",
    "    \n",
    "#     for edge in E:\n",
    "#         u, t = edge['u'], edge['t']\n",
    "#         outgoing_degree[u] += 1\n",
    "#         for node, degree in outgoing_degree.items():\n",
    "#             temporal_outgoing_degree[node].append((t, degree))\n",
    "    \n",
    "#     return temporal_outgoing_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal_outgoing_degree = compute_temporal_outgoing_degree(edges_new)\n",
    "# temporal_outgoing_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def compute_overall_outgoing_degree(E):\n",
    "    # Convert E to a numpy array if it's not already\n",
    "    E = np.array(E, dtype=[('u', int), ('v', int), ('t', float)])\n",
    "    \n",
    "    # Use Counter to count the occurrences of each source node\n",
    "    outgoing_degree = Counter(E['u'])\n",
    "    \n",
    "    return dict(outgoing_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_outgoing_degree = compute_overall_outgoing_degree(edges_new)\n",
    "len(temporal_outgoing_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ts_tpr))\n",
    "print(len(ts_tpr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ts_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract timestamps and PageRank values\n",
    "timestamps, pagerank_arrays = zip(*ts_tpr)\n",
    "timestamps = np.array(timestamps)\n",
    "pagerank_arrays = np.array(pagerank_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank_arrays.shape, len(graph_df['ts']),  len(graph_df['u'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(temporal_outgoing_degree)\n",
    "\n",
    "for key, val in temporal_outgoing_degree.items():\n",
    "    print(key, val)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_to_node_dict = dict(zip(*graph_df[['u', 'ts']]))\n",
    "# ts_to_node_dict\n",
    "\n",
    "ts_to_node_dict = graph_df[['u', 'ts']].set_index('ts').to_dict()['u']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ter_dict = {}\n",
    "# ts_to_node_dict = graph_df[['u', 'ts']].set_index('ts').to_dict()['u']\n",
    "ts_to_node_dict = graph_df.groupby('ts')['u'].apply(list).to_dict()\n",
    "\n",
    "cntr = 0\n",
    "for i in tqdm(range(len(timestamps)), desc='Calculating TER'):\n",
    "    if cntr == 10:\n",
    "        break\n",
    "    r = pagerank_arrays[i]\n",
    "    ts = timestamps[i]\n",
    "    node_list = ts_to_node_dict[ts]\n",
    "    # tpr_t = [r[node] for node in node_list]\n",
    "    # outgoing_degree_node = [temporal_outgoing_degree[node] for node in node_list]\n",
    "    \n",
    "    # ter_dict[ts] = tpr_t / outgoing_degree_node\n",
    "    ter = [r[node] / temporal_outgoing_degree[node] for node in node_list]\n",
    "    \n",
    "    ter_dict[ts] = np.sum(ter)  # can we use mean here?\n",
    "    # cntr+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_strictly_increasing(alist):\n",
    "    return all(x < y for x, y in zip(alist, alist[1:]))\n",
    "\n",
    "\n",
    "\n",
    "is_strictly_increasing(list(ter_dict.values()))\n",
    "\n",
    "# sorted(ter_dict.items(), key = lambda x: x[1])\n",
    "\n",
    "sorted_dict = dict(sorted(ter_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(ter_dict) how do I account for multiple nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def compute_overall_outgoing_degree(E):\n",
    "    # Convert E to a numpy array if it's not already\n",
    "    E = np.array(E, dtype=[('u', int), ('v', int), ('t', float)])\n",
    "    \n",
    "    # Use Counter to count the occurrences of each source node\n",
    "    outgoing_degree = Counter(E['u'])\n",
    "    \n",
    "    return dict(outgoing_degree)\n",
    "\n",
    "\n",
    "def calculate_temporal_edge_rank(_graph_df, beta = 0.85, alpha = 0.15):\n",
    "    graph_df = _graph_df.copy(deep=True)\n",
    "    \n",
    "    # Extract nodes, edges, and timestamps\n",
    "    edges = graph_df[['u', 'i', 'ts']].values\n",
    "    \n",
    "    # Convert E to a more readable format if needed\n",
    "    edges_new = [(int(u), int(v), float(t)) for u, v, t in edges]\n",
    "    \n",
    "    _, ts_tpr= temporal_pagerank_heap_np(edges_new, beta, alpha, True)\n",
    "    temporal_outgoing_degree = compute_overall_outgoing_degree(edges_new)\n",
    "    \n",
    "    # Extract timestamps and PageRank values\n",
    "    timestamps, pagerank_arrays = zip(*ts_tpr)\n",
    "    timestamps = np.array(timestamps)\n",
    "    pagerank_arrays = np.array(pagerank_arrays)\n",
    "    \n",
    "    ts_to_node_dict = graph_df.groupby('ts')['u'].apply(list).to_dict()\n",
    "    \n",
    "    ter_dict = {}\n",
    "    \n",
    "    for i in tqdm(range(len(timestamps)), desc='Calculating TER'):\n",
    "        r = pagerank_arrays[i]\n",
    "        ts = timestamps[i]\n",
    "        node_list = ts_to_node_dict[ts]\n",
    "        ter = [r[node] / temporal_outgoing_degree[node] for node in node_list]\n",
    "        \n",
    "        ter_dict[ts] = np.sum(ter)  # can we use mean here?\n",
    "    \n",
    "    return ter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating TER: 100%|██████████| 157474/157474 [00:01<00:00, 148509.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "152757"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ter_dict = calculate_temporal_edge_rank(graph_df)\n",
    "len(new_ter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import heapq\n",
    "\n",
    "def compute_overall_outgoing_degree(E):\n",
    "    return Counter(E['u'])\n",
    "\n",
    "def calculate_temporal_edge_rank(_graph_df, beta=0.85, alpha=0.15):\n",
    "    graph_df = _graph_df.copy(deep=True)\n",
    "    \n",
    "    # Extract nodes, edges, and timestamps as a list of tuples\n",
    "    edges = graph_df[['u', 'i', 'ts']].values.tolist()\n",
    "    edges = [(int(u), int(v), float(t)) for u, v, t in edges]\n",
    "    \n",
    "    _, ts_tpr = temporal_pagerank_heap_np(edges, beta, alpha, True)\n",
    "    \n",
    "    # Create numpy array for efficient operations\n",
    "    edges_array = np.array(edges, dtype=[('u', int), ('v', int), ('t', float)])\n",
    "    temporal_outgoing_degree = compute_overall_outgoing_degree(edges_array)\n",
    "    \n",
    "    # Extract timestamps and PageRank values\n",
    "    timestamps, pagerank_arrays = zip(*ts_tpr)\n",
    "    timestamps = np.array(timestamps)\n",
    "    pagerank_arrays = np.array(pagerank_arrays)\n",
    "    \n",
    "    ts_to_node_dict = graph_df.groupby('ts')['u'].apply(np.array).to_dict()\n",
    "    \n",
    "    ter_dict = {}\n",
    "    \n",
    "    for i in tqdm(range(len(timestamps)), desc='Calculating TER'):\n",
    "        r = pagerank_arrays[i]\n",
    "        ts = timestamps[i]\n",
    "        node_list = ts_to_node_dict[ts]\n",
    "        ter = r[node_list] / np.vectorize(temporal_outgoing_degree.__getitem__)(node_list)\n",
    "        ter_dict[ts] = np.sum(ter)\n",
    "    \n",
    "    return ter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating TER: 100%|██████████| 157474/157474 [00:04<00:00, 33392.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "152757"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ter_dict = calculate_temporal_edge_rank(graph_df)\n",
    "len(new_ter_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New attempts for a comprehensive TER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the global Temporal PageRank\n",
    "def compute_global_temporal_pagerank(edges, beta=0.85, alpha=0.15):\n",
    "    # Use your existing Temporal PageRank calculation method (e.g., temporal_pagerank_heap_np)\n",
    "    # This should return a dictionary with nodes as keys and global TPR as values\n",
    "    global_tpr, _ = temporal_pagerank_heap_np(edges, beta, alpha, False)\n",
    "    return global_tpr\n",
    "\n",
    "# Function to compute timestamp-specific Temporal PageRank\n",
    "def compute_timestamp_specific_temporal_pagerank(edges, beta=0.85, alpha=0.15):\n",
    "    # Use your existing Temporal PageRank calculation method with timestamp-specific mode\n",
    "    # This should return a list of (timestamp, dict) where dict contains node-specific TPR\n",
    "    _, ts_tpr = temporal_pagerank_heap_np(edges, beta, alpha, True)\n",
    "    return ts_tpr\n",
    "\n",
    "# Function to compute the outgoing degree of nodes globally\n",
    "def compute_global_outgoing_degree(edges):\n",
    "    edges = np.array(edges, dtype=[('u', int), ('v', int), ('t', float)])\n",
    "    u_values = edges['u'].tolist()\n",
    "    return dict(Counter(u_values))\n",
    "\n",
    "# Function to compute the outgoing degree of nodes at specific timestamps\n",
    "def compute_timestamp_specific_outgoing_degree(edges):\n",
    "    edges_by_ts = defaultdict(list)\n",
    "    for u, v, t in edges:\n",
    "        edges_by_ts[t].append((u, v))\n",
    "    \n",
    "    ts_outgoing_degree = {}\n",
    "    for t, edge_list in tqdm(edges_by_ts.items()):\n",
    "        ts_outgoing_degree[t] = dict(Counter([u for u, _ in edge_list]))\n",
    "    \n",
    "    return ts_outgoing_degree\n",
    "\n",
    "\n",
    "def compute_cumulative_timestamp_specific_outgoing_degree(graph_df):\n",
    "    # Sort by timestamp to ensure cumulative counting is correct\n",
    "    graph_df = graph_df.sort_values('ts')\n",
    "    \n",
    "    # Initialize cumulative outgoing degree dictionary\n",
    "    cumulative_outgoing_degree = defaultdict(int)\n",
    "    \n",
    "    # Initialize result dictionary\n",
    "    ts_outgoing_degree = {}\n",
    "    \n",
    "    # Iterate through the DataFrame row by row\n",
    "    for ts, group in tqdm(graph_df.groupby('ts'), desc=\"Calculating cumulative outgoing degree\"):\n",
    "        # Update cumulative counts\n",
    "        for u in group['u']:\n",
    "            cumulative_outgoing_degree[u] += 1\n",
    "            \n",
    "        # Store the current cumulative counts in the result dictionary\n",
    "        ts_outgoing_degree[ts] = dict(cumulative_outgoing_degree)\n",
    "    \n",
    "    return ts_outgoing_degree\n",
    "\n",
    "\n",
    "\n",
    "# Function to compute Temporal EdgeRank for each edge\n",
    "def compute_temporal_edgerank(graph_df, beta=0.85, alpha=0.15, gamma=0.5):\n",
    "    edges_list = graph_df[['u', 'i', 'ts']].values\n",
    "    edges = np.array(\n",
    "        list(zip(edges_list[:, 0].astype(int), edges_list[:, 1].astype(int), edges_list[:, 2].astype(float))),\n",
    "        dtype=[('u', int), ('v', int), ('t', float)]\n",
    "    )\n",
    "    \n",
    "    # edges\n",
    "    print(f'Calculating TPR...', end='\\r')\n",
    "    global_tpr, ts_tpr = temporal_pagerank_heap_np(edges, beta, alpha, True)\n",
    "    # Convert ts_tpr to a dictionary with timestamps as keys\n",
    "    ts_tpr = {row['t']: row['r'] for row in ts_tpr}\n",
    "    print(f'Calculated TPR      ')\n",
    "    \n",
    "    # ts_tpr = compute_timestamp_specific_temporal_pagerank(edges, beta, alpha)  # redundant\n",
    "    print(f'Calculating global_out_deg...', end='\\r')\n",
    "    global_out_deg = compute_global_outgoing_degree(edges)\n",
    "    print(f'Calculated global_out_deg      ')\n",
    "    print(f'Calculating cumulative_timestamp_specific_outgoing_degree...', end='\\r')\n",
    "    ts_out_deg = compute_cumulative_timestamp_specific_outgoing_degree(graph_df[['u', 'i', 'ts']])\n",
    "    print(f'Calculated cumulative_timestamp_specific_outgoing_degree       ')\n",
    "    \n",
    "    ter_dict = {}\n",
    "\n",
    "    for u, _, t in tqdm((edges), desc='Processing'):\n",
    "        TER_global = global_tpr[u] / global_out_deg[u]\n",
    "        TER_ts = ts_tpr[t][u] / ts_out_deg[t][u]\n",
    "        ter_ts = gamma * TER_global + (1 - gamma) * TER_ts\n",
    "        ter_dict[t] = ter_ts\n",
    "        \n",
    "    return ter_dict\n",
    "\n",
    "# Main function to call and calculate Combined Temporal EdgeRank\n",
    "def calculate_combined_temporal_edgerank(graph_df, beta=0.85, alpha=0.15, gamma=0.5):\n",
    "    \n",
    "    return compute_temporal_edgerank(graph_df, beta, alpha, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated TPR      \n",
      "Calculated global_out_deg      \n",
      "Calculating cumulative_timestamp_specific_outgoing_degree...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating cumulative outgoing degree: 100%|██████████| 152757/152757 [00:53<00:00, 2864.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated cumulative_timestamp_specific_outgoing_degree       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 157474/157474 [00:01<00:00, 123214.32it/s]\n"
     ]
    }
   ],
   "source": [
    "combined_ter_dict = calculate_combined_temporal_edgerank(graph_df=graph_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152757, 157474)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_ter_dict), len(graph_df['ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157474"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
